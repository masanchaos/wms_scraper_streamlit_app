import streamlit as st
import pandas as pd
import pyperclip
import datetime
import time
import json
import os
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, ElementClickInterceptedException, NoSuchElementException

# =================================================================================
# æ ¸å¿ƒçˆ¬èŸ²èˆ‡è³‡æ–™è™•ç†é‚è¼¯ (èˆ‡å‰ä¸€ç‰ˆç›¸åŒ)
# =================================================================================

class WmsScraper:
    # ... ç‚ºäº†ç¯€çœç¯‡å¹…ï¼Œæ­¤è™•çœç•¥ WmsScraper class çš„å®Œæ•´ç¨‹å¼ç¢¼ ...
    # ... è«‹ä½¿ç”¨æ‚¨ç¾æœ‰çš„ã€å¯æˆåŠŸé‹ä½œçš„ç‰ˆæœ¬å³å¯ ...
    def __init__(self, url, username, password, status_callback=None):
        self.url = url
        self.username = username
        self.password = password
        self.status_callback = status_callback

    def _update_status(self, message):
        if self.status_callback:
            self.status_callback(message)

    def _login(self, driver):
        self._update_status("  > æ­£åœ¨å‰å¾€ç™»å…¥é é¢...")
        driver.get(self.url)
        account_xpath = "//input[@placeholder='example@jenjan.com.tw']"
        password_xpath = "//input[@type='password']"
        account_input = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, account_xpath)))
        account_input.click()
        account_input.send_keys(self.username)
        password_input = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, password_xpath)))
        password_input.click()
        password_input.send_keys(self.password)
        password_input.send_keys(Keys.ENTER)
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, "app")))
        self._update_status("âœ… [æˆåŠŸ] ç™»å…¥å®Œæˆï¼")
        self._update_status("  > ç­‰å¾…ä¸»é é¢ç©©å®š...")
        time.sleep(5)

    def _navigate_to_picking_complete(self, driver):
        self._update_status("  > å°‹æ‰¾å°è¦½èœå–®...")
        picking_management_xpath = "//a[@href='/admin/pickup']"
        try:
            picking_management_button = WebDriverWait(driver, 30).until(
                EC.element_to_be_clickable((By.XPATH, picking_management_xpath))
            )
            picking_management_button.click()
        except Exception as e:
            self._update_status("  > â—ï¸ è‡´å‘½éŒ¯èª¤ï¼šç„¡æ³•æ‰¾åˆ°æˆ–é»æ“Šå°è¦½èœå–®ã€‚")
            raise e

        self._update_status("  > æ­£åœ¨ç­‰å¾…åˆ†é å€å¡Šè¼‰å…¥...")
        default_tab_xpath = "//div[contains(@class, 'btn') and (contains(., 'æœªæ€è¨‚å–®') or contains(., 'Unpicked'))]"
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.XPATH, default_tab_xpath)))
        
        self._update_status("  > é»æ“Šã€Œæ€åŒ…å®Œæˆã€åˆ†é æŒ‰éˆ•...")
        picking_complete_tab_xpath = "//div[contains(@class, 'btn') and (contains(., 'æ€åŒ…å®Œæˆ') or contains(., 'Complete'))]"
        WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, picking_complete_tab_xpath))).click()
        self._update_status("âœ… [æˆåŠŸ] å·²é€²å…¥æ€åŒ…å®Œæˆé é¢ï¼")
        
    def _scrape_data(self, driver):
        self._update_status("  > é»æ“ŠæŸ¥è©¢æŒ‰éˆ•ä»¥è¼‰å…¥è³‡æ–™...")
        query_button_xpath = "//div[contains(@class, 'btn-primary')]"
        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, query_button_xpath))).click()
        WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.XPATH, "//div[contains(@class, 'list-items')]/div[contains(@class, 'item')]")))
        self._update_status("  > è³‡æ–™å·²åˆæ­¥è¼‰å…¥ã€‚")
        
        all_data = []
        page_count = 1
        while True:
            self._update_status(f"  > æ­£åœ¨æŠ“å–ç¬¬ {page_count} é çš„è³‡æ–™...")
            time.sleep(1.5)
            item_rows_xpath = "//div[contains(@class, 'list-items')]/div[contains(@class, 'item')]"
            rows = driver.find_elements(By.XPATH, item_rows_xpath)
            if not rows: break
            for row in rows:
                shipping_method, tracking_code = "", ""
                try:
                    shipping_method = row.find_element(By.XPATH, "./div[2]/div[3]").text.strip()
                    tracking_code_input = row.find_element(By.XPATH, "./div[2]/div[4]//input")
                    tracking_code = tracking_code_input.get_property('value').strip()
                    if shipping_method or tracking_code:
                        all_data.append({"å¯„é€æ–¹å¼": shipping_method, "ä¸»è¦é‹é€ä»£ç¢¼": tracking_code})
                except Exception: continue
            try:
                next_button_xpath = "//button[normalize-space()='ä¸‹ä¸€é ' or normalize-space()='Next']"
                next_button = driver.find_element(By.XPATH, next_button_xpath)
                if next_button.get_attribute('disabled'): break
                else:
                    driver.execute_script("arguments[0].click();", next_button)
                    page_count += 1
                    WebDriverWait(driver, 10).until(EC.staleness_of(rows[0]))
            except Exception: break
        return all_data

    def run(self):
        chrome_options = Options()
        chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        
        driver = None
        try:
            self._update_status("  > æ­£åœ¨åˆå§‹åŒ– WebDriver...")
            driver = webdriver.Chrome(options=chrome_options)
            driver.set_window_size(1920, 1080)
            
            self._login(driver)
            self._navigate_to_picking_complete(driver)
            time.sleep(3)
            data = self._scrape_data(driver)
            
            self._update_status("âœ… [æˆåŠŸ] æ‰€æœ‰è³‡æ–™æŠ“å–å®Œæˆï¼")
            return pd.DataFrame(data)
        finally:
            if driver:
                driver.quit()

# ... generate_report_text å’Œ process_and_output_data ä¿æŒä¸è®Š...
def generate_report_text(df_to_process, display_timestamp, report_title):
    # ... (çœç•¥æœªè®Šå‹•çš„ç¨‹å¼ç¢¼) ...
    pass
def process_and_output_data(df, status_callback):
    # ... (çœç•¥æœªè®Šå‹•çš„ç¨‹å¼ç¢¼) ...
    pass


# =================================================================================
# æ–°å¢ï¼šæ†‘è­‰è™•ç†å‡½å¼
# =================================================================================
CREDENTIALS_FILE = "credentials.json"

def load_credentials():
    """å¾ä¼ºæœå™¨ä¸Šçš„æª”æ¡ˆè¼‰å…¥å·²å„²å­˜çš„å¸³è™Ÿå¯†ç¢¼"""
    if os.path.exists(CREDENTIALS_FILE):
        try:
            with open(CREDENTIALS_FILE, 'r') as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return {} # å¦‚æœæª”æ¡ˆæ¯€ææˆ–æ‰¾ä¸åˆ°ï¼Œè¿”å›ç©ºå­—å…¸
    return {}

def save_credentials(username, password):
    """å°‡å¸³è™Ÿå¯†ç¢¼å„²å­˜åˆ°ä¼ºæœå™¨ä¸Šçš„æª”æ¡ˆ"""
    with open(CREDENTIALS_FILE, 'w') as f:
        json.dump({"username": username, "password": password}, f)

def clear_credentials():
    """å¾ä¼ºæœå™¨ä¸Šåˆªé™¤å·²å„²å­˜çš„å¸³è™Ÿå¯†ç¢¼æª”æ¡ˆ"""
    if os.path.exists(CREDENTIALS_FILE):
        os.remove(CREDENTIALS_FILE)


# =================================================================================
# Streamlit å‰ç«¯ä»‹é¢è¨­è¨ˆ (å·²æ›´æ–°)
# =================================================================================

st.set_page_config(page_title="WMS ç‰©æµè³‡æ–™æ“·å–å·¥å…·", page_icon="ğŸšš", layout="wide")

# --- åˆå§‹åŒ– Session State ---
if 'scraping_done' not in st.session_state:
    st.session_state.scraping_done = False
if 'final_df' not in st.session_state:
    st.session_state.final_df = pd.DataFrame()
if 'report_texts' not in st.session_state:
    st.session_state.report_texts = {}

# --- å´é‚Šæ¬„ï¼šè¨­å®šå€ (å·²æ›´æ–°) ---
with st.sidebar:
    
    st.header("âš™ï¸ é€£çµèˆ‡ç™»å…¥è¨­å®š")

    # è¼‰å…¥å·²å„²å­˜çš„æ†‘è­‰
    saved_creds = load_credentials()
    saved_username = saved_creds.get("username", "")
    saved_password = saved_creds.get("password", "")

    url = st.text_input("ç›®æ¨™ç¶²é  URL", value="https://wms.jenjan.com.tw/")
    
    # è¼¸å…¥æ¡†çš„é è¨­å€¼ä¾†è‡ªè¼‰å…¥çš„æ†‘è­‰
    username = st.text_input("å¸³è™Ÿ", value=saved_username)
    password = st.text_input("å¯†ç¢¼", value=saved_password, type="password")
    
    # æ–°å¢ã€Œè¨˜ä½æˆ‘ã€åŠŸèƒ½
    remember_me = st.checkbox("è¨˜ä½æˆ‘ (ä¸‹æ¬¡è‡ªå‹•å¡«å…¥å¸³å¯†)")
    
    st.warning("âš ï¸ **å®‰å…¨æ€§æé†’**:\nå‹¾é¸ã€Œè¨˜ä½æˆ‘ã€æœƒå°‡å¸³å¯†ä»¥å¯è®€å–çš„å½¢å¼ä¿å­˜åœ¨ä¼ºæœå™¨ä¸Šã€‚åƒ…å»ºè­°åœ¨æ‚¨ä¿¡ä»»æ­¤æœå‹™ä¸”å¸³è™Ÿéé«˜åº¦æ•æ„Ÿçš„æƒ…æ³ä¸‹ä½¿ç”¨ã€‚")
    

# --- ä¸»é é¢ï¼šæ¨™é¡Œèˆ‡æ§åˆ¶å€ ---
st.title("ğŸšš WMS ç¶²é è³‡æ–™æ“·å–å·¥å…·")
st.markdown("---")

start_button = st.button("ğŸš€ é–‹å§‹æ“·å–è³‡æ–™", type="primary", use_container_width=True)

if start_button:
    # --- æ–°å¢ï¼šè™•ç†ã€Œè¨˜ä½æˆ‘ã€çš„é‚è¼¯ ---
    if remember_me:
        save_credentials(username, password)
    else:
        clear_credentials()

    # --- åŸ·è¡Œçˆ¬èŸ² (èˆ‡ä¹‹å‰ç›¸åŒ) ---
    st.session_state.scraping_done = False
    status_area = st.empty()

    def streamlit_callback(message):
        status_area.info(message)

    with st.spinner("æ­£åœ¨åŸ·è¡Œä¸­ï¼Œè«‹å‹¿é—œé–‰è¦–çª—..."):
        try:
            # ç¢ºä¿ä½¿ç”¨è€…æœ‰è¼¸å…¥å¸³å¯†
            if not username or not password:
                status_area.error("âŒ è«‹å‹™å¿…è¼¸å…¥å¸³è™Ÿå’Œå¯†ç¢¼ï¼")
            else:
                scraper = WmsScraper(url, username, password, status_callback=streamlit_callback)
                result_df = scraper.run()
                
                if not result_df.empty:
                    # (ç‚ºäº†ç¯€çœç¯‡å¹…ï¼Œæ­¤è™•çœç•¥ process_and_output_data çš„å‘¼å«ï¼Œæ‚¨ç¾æœ‰çš„ç‰ˆæœ¬å³å¯)
                    st.session_state.scraping_done = True
                    status_area.success("ğŸ‰ æ‰€æœ‰ä»»å‹™å®Œæˆï¼è«‹æŸ¥çœ‹ä¸‹æ–¹çš„çµæœã€‚")
                else:
                    status_area.warning("âš ï¸ æŠ“å–å®Œæˆï¼Œä½†æ²’æœ‰æ”¶åˆ°ä»»ä½•è³‡æ–™ã€‚")

        except Exception as e:
            st.session_state.scraping_done = False
            status_area.error(f"âŒ åŸ·è¡Œæ™‚ç™¼ç”Ÿè‡´å‘½éŒ¯èª¤ï¼š")
            st.exception(e)

# --- çµæœé¡¯ç¤ºå€ (èˆ‡ä¹‹å‰ç›¸åŒ) ---
if st.session_state.scraping_done:
    st.markdown("---")
    st.header("ğŸ“Š æ“·å–çµæœ")
    # ... (çœç•¥æœªè®Šå‹•çš„ UI ç¨‹å¼ç¢¼) ...
